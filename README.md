# GameofThrones-text-generation-LSTMs
#### The project utilizes LSTMs architecture in the recurrent neural network model to generate/predict/output a 25-word text sequence after inputting a 25-word text sequence. The model is trained using the Game of thrones fictional book in the form of a text file.
## Dataset
#### The dataset used in this project is a desired text segment from the Game of Thrones text file. It selects from indices 0-50000 for computational purposes.
## Results
#### The LSTMS-based model was able to train and fit to the input text at  90 percent accuracy and 0.4 categorical cross entropy loss, which is excellent. It would output the next 25-word text sequence after inputting a 25-word text sequence.
## Future improvements and uses
#### 1. Hyperparameter tuning to improve the model and train on a larger and more diverse dataset
#### 2. Build a chatbot that can generate conversational responses based on user queries
#### 3. Develop a creative writing assistant that can help writers complete sentences after providing a partial sentence or prompt
## Contributing
#### Contributions to this project are welcome. If you have any suggestions, bug reports, or would like to contribute new features or improvements, please submit a pull request.
